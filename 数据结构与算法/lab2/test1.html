<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>[2201.11903] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</title>

  <link rel="canonical" href="https://arxiv.org/abs/2201.11903" />

  <meta name="description" content="Abstract page for arXiv paper 2201.11903: Chain-of-Thought Prompting Elicits Reasoning in Large Language Models" />
  <meta property="og:type" content="website" />
  <meta property="og:site_name" content="arXiv.org" />
  <meta property="og:title" content="Chain-of-Thought Prompting Elicits Reasoning in Large Language Models" />
  <meta property="og:url" content="https://arxiv.org/abs/2201.11903v6" />
  <meta name="twitter:card" content="summary" />
  <meta name="twitter:site" content="@arxiv" />

  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, "Apple Color Emoji", "Segoe UI Emoji"; line-height: 1.6; margin: 2rem; color: #111; }
    header h1 { font-size: 1rem; font-weight: 600; color: #666; margin: 0 0 .5rem; }
    main h1 { font-size: 1.6rem; margin: .25rem 0 1rem; }
    .authors a { text-decoration: none; color: #0645ad; }
    .meta { margin: 1rem 0; }
    .meta dt { float: left; width: 7.5rem; color: #444; font-weight: 600; }
    .meta dd { margin: 0 0 .5rem 7.5rem; }
    blockquote { background: #f7f7f7; border-left: 4px solid #ddd; margin: 1rem 0; padding: .75rem 1rem; }
    .links a { display: inline-block; margin-right: .75rem; text-decoration: none; color: #0645ad; }
    footer { margin-top: 2rem; font-size: .9375rem; color: #555; }
    hr { border: 0; border-top: 1px solid #e5e5e5; margin: 1.5rem 0; }
  </style>
</head>
<body>
  <header>
    <h1>Computer Science &gt; Computation and Language (cs.CL)</h1>
  </header>

  <main>
    <section>
      <div class="dateline">Submitted on 28 Jan 2022; last revised 10 Jan 2023 (v6)</div>
      <h1>Chain-of-Thought Prompting Elicits Reasoning in Large Language Models</h1>

      <div class="authors">
        <strong>Authors:</strong>
        <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wei%2C+J" rel="nofollow">Jason Wei</a>,
        <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+X" rel="nofollow">Xuezhi Wang</a>,
        <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schuurmans%2C+D" rel="nofollow">Dale Schuurmans</a>,
        <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bosma%2C+M" rel="nofollow">Maarten Bosma</a>,
        <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ichter%2C+B" rel="nofollow">Brian Ichter</a>,
        <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xia%2C+F" rel="nofollow">Fei Xia</a>,
        <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chi%2C+E" rel="nofollow">Ed Chi</a>,
        <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Le%2C+Q" rel="nofollow">Quoc Le</a>,
        <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhou%2C+D" rel="nofollow">Denny Zhou</a>
      </div>

      <blockquote class="abstract">
        <strong>Abstract:</strong>
        We explore how generating a chain of thought — a series of intermediate reasoning steps — significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.
      </blockquote>

      <dl class="meta">
        <dt>Subjects:</dt>
        <dd><span class="primary-subject">Computation and Language (cs.CL)</span>; Artificial Intelligence (cs.AI)</dd>

        <dt>Cite as:</dt>
        <dd><a href="https://arxiv.org/abs/2201.11903">arXiv:2201.11903</a> [cs.CL] (v6)</dd>

        <dt>DOI:</dt>
        <dd><a href="https://doi.org/10.48550/arXiv.2201.11903">10.48550/arXiv.2201.11903</a></dd>
      </dl>

      <div class="links">
        <a href="https://arxiv.org/pdf/2201.11903" rel="noopener">View PDF</a>
        <a href="https://arxiv.org/src/2201.11903" rel="noopener">TeX Source</a>
      </div>

      <hr />

      <section aria-labelledby="history-title">
        <h2 id="history-title" style="font-size:1.1rem;margin:.5rem 0 0.75rem;">Submission history</h2>
        <p>
          [v1] Fri, 28 Jan 2022 02:33:07 UTC (944 KB)<br />
          [v2] Wed, 6 Apr 2022 03:51:50 UTC (933 KB)<br />
          [v3] Wed, 1 Jun 2022 00:10:30 UTC (303 KB)<br />
          [v4] Mon, 13 Jun 2022 21:44:34 UTC (283 KB)<br />
          [v5] Mon, 10 Oct 2022 20:21:17 UTC (285 KB)<br />
          [v6] Tue, 10 Jan 2023 23:07:57 UTC (306 KB)
        </p>
      </section>
    </section>
  </main>

  <footer>
    <p>Source: <a href="https://arxiv.org/abs/2201.11903">https://arxiv.org/abs/2201.11903</a></p>
  </footer>
</body>
</html>