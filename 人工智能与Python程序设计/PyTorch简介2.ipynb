{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "t.Tensor(3, 4)\n",
    "print(t.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6862, 0.1404, 0.5759, 0.0975],\n",
       "         [0.3727, 0.9210, 0.8898, 0.1087],\n",
       "         [0.9427, 0.0550, 0.5798, 0.9759]],\n",
       "\n",
       "        [[0.9131, 0.9198, 0.1288, 0.7288],\n",
       "         [0.1218, 0.1987, 0.9134, 0.9135],\n",
       "         [0.2459, 0.1575, 0.3379, 0.4578]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成一个随机Tensor\n",
    "x = t.rand(2, 3, 4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "2 3 4\n"
     ]
    }
   ],
   "source": [
    "# 查看x的形状\n",
    "print(x.size())\n",
    "\n",
    "print(x.size()[0], x.size()[1], x.size()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.3477, 0.9416, 1.2259, 0.9429],\n",
       "         [0.8617, 1.2446, 1.3937, 0.6304],\n",
       "         [1.1212, 0.2298, 1.3218, 1.4356]],\n",
       "\n",
       "        [[1.3775, 1.1209, 0.5950, 1.5023],\n",
       "         [0.5283, 0.4836, 1.5175, 1.2425],\n",
       "         [0.7684, 0.6490, 1.2174, 0.6276]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#两个Tensor相加\n",
    "y = t.rand(2, 3, 4)\n",
    "z = x + y\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 注意两个张量对应的维度要匹配\u001b[39;00m\n\u001b[1;32m      2\u001b[0m y1 \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m z1 \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m y1\n\u001b[1;32m      4\u001b[0m z1\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "# 注意两个张量对应的维度要匹配\n",
    "y1 = t.rand(3, 4, 2)\n",
    "z1 = x + y1\n",
    "z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.3477, 0.9416, 1.2259, 0.9429],\n",
      "         [0.8617, 1.2446, 1.3937, 0.6304],\n",
      "         [1.1212, 0.2298, 1.3218, 1.4356]],\n",
      "\n",
      "        [[1.3775, 1.1209, 0.5950, 1.5023],\n",
      "         [0.5283, 0.4836, 1.5175, 1.2425],\n",
      "         [0.7684, 0.6490, 1.2174, 0.6276]]])\n"
     ]
    }
   ],
   "source": [
    "#通过函数add实现加法\n",
    "print(t.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([1, 3, 1])\n",
      "torch.Size([2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "x = t.rand(2,3,4)\n",
    "y = t.rand(1,3,1)\n",
    "z = x + y\n",
    "print(x.size())\n",
    "print(y.size())\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m z \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m y\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(x\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (2) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "x = t.rand(2,3,4)\n",
    "y = t.rand(1,3,2)\n",
    "z = x + y\n",
    "print(x.size())\n",
    "print(y.size())\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9585, 1.2435, 1.2089, 0.6691],\n",
       "         [1.0728, 0.7058, 1.3123, 0.5184],\n",
       "         [1.4150, 1.2051, 1.0735, 1.0385]],\n",
       "\n",
       "        [[0.7554, 1.0544, 1.3630, 1.2955],\n",
       "         [1.7007, 1.7571, 0.8237, 0.6010],\n",
       "         [1.0906, 1.1719, 1.0333, 1.8185]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#另外一个写法，结果输出到提前定义好的Tensor中\n",
    "result = t.Tensor(2, 3, 4)\n",
    "x = t.rand(2, 3, 4)\n",
    "y = t.rand(2, 3, 4)\n",
    "t.add(x, y, out = result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3912, 0.9108, 0.9038, 0.3977],\n",
      "         [0.8235, 0.6576, 0.7737, 0.4148],\n",
      "         [0.6547, 0.4639, 0.6549, 0.2668]],\n",
      "\n",
      "        [[0.1422, 0.0686, 0.8640, 0.3267],\n",
      "         [0.7307, 0.7678, 0.3851, 0.0465],\n",
      "         [0.3102, 0.8771, 0.3160, 0.8350]]])\n",
      "tensor([[[0.3912, 0.9108, 0.9038, 0.3977],\n",
      "         [0.8235, 0.6576, 0.7737, 0.4148],\n",
      "         [0.6547, 0.4639, 0.6549, 0.2668]],\n",
      "\n",
      "        [[0.1422, 0.0686, 0.8640, 0.3267],\n",
      "         [0.7307, 0.7678, 0.3851, 0.0465],\n",
      "         [0.3102, 0.8771, 0.3160, 0.8350]]])\n",
      "tensor([[[0.9585, 1.2435, 1.2089, 0.6691],\n",
      "         [1.0728, 0.7058, 1.3123, 0.5184],\n",
      "         [1.4150, 1.2051, 1.0735, 1.0385]],\n",
      "\n",
      "        [[0.7554, 1.0544, 1.3630, 1.2955],\n",
      "         [1.7007, 1.7571, 0.8237, 0.6010],\n",
      "         [1.0906, 1.1719, 1.0333, 1.8185]]])\n"
     ]
    }
   ],
   "source": [
    "# 函数名带下划线 x.add_(y)会改变x，不带下划线x.add(y) 返回一个新的Tensor，x不改变\n",
    "print(x)\n",
    "x.add(y)\n",
    "print(x)\n",
    "x.add_(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2., -2., -2.],\n",
      "        [-2., -2., -2.]])\n"
     ]
    }
   ],
   "source": [
    "a =t.ones(2, 3)\n",
    "b = 3.0 * t.ones(2, 3)\n",
    "c = a - b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m d \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m e \u001b[38;5;241m=\u001b[39m a \u001b[38;5;241m-\u001b[39m d\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "d = t.ones(2,2)\n",
    "e = a - d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[ 2.,  4.],\n",
      "        [ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "tensor([[ 2.,  8.],\n",
      "        [18., 32.],\n",
      "        [50., 72.]])\n",
      "tensor(182.)\n",
      "tensor([[ 10.,  22.,  34.],\n",
      "        [ 22.,  50.,  78.],\n",
      "        [ 34.,  78., 122.]])\n",
      "tensor([[ 70.,  88.],\n",
      "        [ 88., 112.]])\n"
     ]
    }
   ],
   "source": [
    "a = t.Tensor([[1,2], [3,4], [5, 6]])\n",
    "print(a)\n",
    "\n",
    "#数乘矩阵\n",
    "b = 2.0 * a\n",
    "print(b)\n",
    "\n",
    "#对应点相乘，sum后即为卷积\n",
    "c = a * b\n",
    "print(c)\n",
    "print(c.sum())\n",
    "\n",
    "# a: 3 * 2, b.t():2 * 3\n",
    "# d: 3 * 3\n",
    "d = a.mm(b.t())\n",
    "print(d)\n",
    "\n",
    "\n",
    "# a.t(): 2 * 3, b.t():3 * 2\n",
    "# e: 2 * 2\n",
    "e = a.t().mm(b)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5., 11., 17., 23.],\n",
      "        [11., 25., 39., 53.],\n",
      "        [17., 39., 61., 83.]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 4x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(c)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#如果矩阵大小不满足 x: i * n, y:n * j的方式，则出错\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m c \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mmm(b)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 4x2)"
     ]
    }
   ],
   "source": [
    "a = t.Tensor([[1,2], [3,4], [5, 6]]) # 3 * 2\n",
    "b = t.Tensor([[1, 2],[3,4],[5,6],[7,8]]) # 4 * 2\n",
    "\n",
    "c = a.mm(b.t()) # 3 * 4 \n",
    "print(c)\n",
    "\n",
    "\n",
    "#如果矩阵大小不满足 x: i * n, y:n * j的方式，则出错\n",
    "c = a.mm(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[1., 2.]])\n",
      "tensor([[ 5.],\n",
      "        [11.],\n",
      "        [17.]])\n",
      "tensor([[ 5., 11., 17.]])\n"
     ]
    }
   ],
   "source": [
    "#A: 3 * 2\n",
    "#x: 1 * 2\n",
    "A = t.Tensor([[1,2], [3,4], [5, 6]]) \n",
    "x = t.Tensor([[1, 2]])\n",
    "print(A)\n",
    "print(x)\n",
    "\n",
    "# A: 3*2; b.t(): 2 * 1\n",
    "# 结果：3 * 1\n",
    "c = A.mm(x.t())\n",
    "print(c)\n",
    "\n",
    "#x: 1 * 2, A.t(): 2 * 3\n",
    "# 结果: 1 * 3\n",
    "d = x.mm(A.t())\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4., 5., 6.]])\n",
      "tensor([[1., 2., 3., 4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "a=t.Tensor([[[1,2,3],[4,5,6]]])\n",
    "b=t.Tensor([1,2,3,4,5,6])\n",
    "\n",
    "print(a.view(1,6))\n",
    "print(b.view(1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2., 3., 4.],\n",
      "         [5., 6., 7., 8.]]])\n",
      "---------------------------------\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n",
      "---------------------------------\n",
      "tensor([[[1., 2.],\n",
      "         [3., 4.]],\n",
      "\n",
      "        [[5., 6.],\n",
      "         [7., 8.]]])\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "a=t.Tensor([[[1,2,3, 4],[5,6,7,8]]])\n",
    "print(a)\n",
    "print('---------------------------------')\n",
    "print(a.view(4,2))\n",
    "print('---------------------------------')\n",
    "print(a.view(2, 2 ,2))\n",
    "print('---------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1918, 0.1022, 0.7519, 0.1538],\n",
      "         [0.4982, 0.1233, 0.7954, 0.8056],\n",
      "         [0.0992, 0.6927, 0.1815, 0.8829]],\n",
      "\n",
      "        [[0.6970, 0.2224, 0.1487, 0.0361],\n",
      "         [0.8382, 0.6988, 0.8047, 0.8188],\n",
      "         [0.6358, 0.5353, 0.6387, 0.3271]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.1918, 0.1022, 0.7519, 0.1538])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor的选取操作与numpy类似\n",
    "x = t.rand(2,3,4)\n",
    "print(x)\n",
    "x[0, 0, :]  #有几个区间就有几个中括号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1918, 0.6970])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0, 0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1918, 0.4982, 0.0992],\n",
       "        [0.6970, 0.8382, 0.6358]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7954, 0.8056],\n",
       "         [0.1815, 0.8829]],\n",
       "\n",
       "        [[0.8047, 0.8188],\n",
       "         [0.6387, 0.3271]]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1:3, 2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6763, 0.2648],\n",
      "        [0.9791, 0.2431]])\n",
      "tensor([[0.2827, 0.9928],\n",
      "        [0.0866, 0.9988]])\n"
     ]
    }
   ],
   "source": [
    "x1 = t.rand(2,2)\n",
    "x2 = t.rand(2,2)\n",
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6763, 0.2648],\n",
      "        [0.9791, 0.2431],\n",
      "        [0.2827, 0.9928],\n",
      "        [0.0866, 0.9988]])\n"
     ]
    }
   ],
   "source": [
    "y = t.cat((x1, x2), dim=0)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6763, 0.2648, 0.2827, 0.9928],\n",
      "        [0.9791, 0.2431, 0.0866, 0.9988]])\n"
     ]
    }
   ],
   "source": [
    "y = t.cat((x1,x2), dim=1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6763, 0.2648],\n",
      "         [0.9791, 0.2431]]])\n",
      "torch.Size([1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "y = x1.unsqueeze(0)\n",
    "print(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6763, 0.2648],\n",
      "        [0.9791, 0.2431]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "y = x1.squeeze(0)\n",
    "print(y)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.6763, 0.2648]]), tensor([[0.9791, 0.2431]]))\n"
     ]
    }
   ],
   "source": [
    "y = t.chunk(x1, 2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1144, 0.7650, 0.9883],\n",
      "        [0.7439, 0.5985, 0.8692]])\n"
     ]
    }
   ],
   "source": [
    "y = t.rand(2,3)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1144, 0.7650],\n",
      "        [0.9883, 0.7439],\n",
      "        [0.5985, 0.8692]])\n",
      "tensor([[0.0000, 0.7650, 0.9883],\n",
      "        [0.7439, 0.5985, 0.8692]])\n"
     ]
    }
   ],
   "source": [
    "y1 = t.reshape(y, (3, 2))\n",
    "print(y1)\n",
    "\n",
    "y1[0,0] = 0\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.7650, 0.9883, 0.7439, 0.5985, 0.8692]])\n"
     ]
    }
   ],
   "source": [
    "y1 = y.reshape(1, -1)\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PyTorch Tensor与Numpy之间的转换\n",
    "#tensor->numpy\n",
    "a = t.ones(2, 3, 4)\n",
    "b = a.numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# numpy --> Tensor\n",
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = t.from_numpy(a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "# 上述转换中，Tensor和Numpy共享内容，所以修改一个另一个也随之改变\n",
    "\n",
    "print(a)\n",
    "b.add_(1) #注意是下划线add_\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[95], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     z \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m y \u001b[38;5;66;03m#在GPU中运算x + y\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     z \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m y\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(z)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (3) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "#支持GPU，将x和y都转移到GPU中进行运算\n",
    "# 在大规模数据复杂Tensor运算时，具有优势；\n",
    "# 小规模数据时由于具有数据转移开销，CPU会更快一点\n",
    "\n",
    "#本机器不支持GPU，不会运行以下代码\n",
    "if t.cuda.is_available():\n",
    "    x = x.cuda() #将张量x转移到GPU中\n",
    "    y = y.cuda() #将张量y转移到GPU中\n",
    "    z = x + y #在GPU中运算x + y\n",
    "else:\n",
    "    z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#如果不进行判断，x.cuda()语句在没有GPU环境的情况下出错\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mcuda() \u001b[38;5;66;03m#将张量x转移到GPU中\u001b[39;00m\n\u001b[1;32m      3\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mcuda() \u001b[38;5;66;03m#将张量y转移到GPU中\u001b[39;00m\n\u001b[1;32m      4\u001b[0m x \u001b[38;5;241m+\u001b[39m y\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:284\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    288\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "#如果不进行判断，x.cuda()语句在没有GPU环境的情况下出错\n",
    "x = x.cuda() #将张量x转移到GPU中\n",
    "y = y.cuda() #将张量y转移到GPU中\n",
    "x + y #在GPU中运算x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "# 求函数 y= x^2 在x=3时的导数: y'(3) = dy/dx|x=3\n",
    "\n",
    "x=t.tensor(3.0,requires_grad=True)\n",
    "y=x.mul(x)\n",
    "\n",
    "#判断x,y是否是可以求导的\n",
    "print(x.requires_grad)\n",
    "print(y.requires_grad)\n",
    "\n",
    "#求导，通过backward函数来实现\n",
    "y.backward()\n",
    "\n",
    "#查看导数，也即所谓的梯度\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# 练习\n",
    "# 求y = max(0, x)在x=1和x=-1处的导数\n",
    "\n",
    "\n",
    "#定义x=1.0 和y=max(0, x)\n",
    "x = t.tensor(1.0, requires_grad=True)\n",
    "y = t.max(x, t.zeros(1,1))\n",
    "\n",
    "#调用backward并打印导数\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "\n",
    "# 改变x后需要重新执行y和backward\n",
    "x = t.tensor(-1.0, requires_grad=True)\n",
    "y = t.max(x, t.zeros(1,1))\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-4.)\n",
      "tensor(-1.)\n",
      "tensor(-0.2500)\n"
     ]
    }
   ],
   "source": [
    "# 求y = 1/x\n",
    "x = t.tensor(0.5, requires_grad=True)\n",
    "y = t.reciprocal(x)\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "\n",
    "x = t.tensor(1.0, requires_grad=True)\n",
    "y = t.reciprocal(x)\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "\n",
    "x = t.tensor(2.0, requires_grad=True)\n",
    "y = t.reciprocal(x)\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.4142)\n",
      "tensor(-0.5000)\n",
      "tensor(-0.1768)\n"
     ]
    }
   ],
   "source": [
    "# 求y = 1/\\sqrt(x)\n",
    "x = t.tensor(0.5, requires_grad=True)\n",
    "y = t.reciprocal( t.sqrt(x))\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "\n",
    "x = t.tensor(1.0, requires_grad=True)\n",
    "y = t.reciprocal( t.sqrt(x))\n",
    "y.backward()\n",
    "print(x.grad)\n",
    "\n",
    "x = t.tensor(2.0, requires_grad=True)\n",
    "y = t.reciprocal( t.sqrt(x))\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000)\n",
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# 求y = 1/\\sqrt(x)\n",
    "x = t.tensor(1.0, requires_grad=True)\n",
    "g = t.sqrt(x)\n",
    "y = t.reciprocal(g)\n",
    "\n",
    "g.backward(retain_graph=True)\n",
    "print(x.grad)\n",
    "\n",
    "\n",
    "y.backward(retain_graph=True)\n",
    "print(x.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.)\n",
      "tensor(5.)\n"
     ]
    }
   ],
   "source": [
    "# f(x,y) = x^2 + 2 * y^2 + xy\n",
    "# 在 (1.0, 1.0)处的导数\n",
    "x = t.tensor(1.0, requires_grad=True)\n",
    "y = t.tensor(1.0, requires_grad=True)\n",
    "\n",
    "f = x.pow(2) + t.tensor(2.0).mul(y.pow(2)) + x.mul(y)\n",
    "f.backward()\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0064)\n",
      "tensor(0.0471)\n",
      "tensor(0.9465)\n"
     ]
    }
   ],
   "source": [
    "# f(x,y, z) = ln(e^x + e^y + e^z)\n",
    "# 在 (0.0, 2.0, 5.0)处的导数\n",
    "x = t.tensor(0.0, requires_grad=True)\n",
    "y = t.tensor(2.0, requires_grad=True)\n",
    "z = t.tensor(5.0, requires_grad=True)\n",
    "\n",
    "f = t.log(t.exp(x) + t.exp(y) + t.exp(z))\n",
    "f.backward()\n",
    "print(x.grad)\n",
    "print(y.grad)\n",
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.]], requires_grad=True) tensor([[1., 1.],\n",
      "        [1., 2.]]) tensor([[1.],\n",
      "        [0.]])\n",
      "\n",
      "tensor([[14.]], grad_fn=<AddBackward0>)\n",
      "\n",
      "tensor([[ 7.],\n",
      "        [10.]])\n"
     ]
    }
   ],
   "source": [
    "# 注意：把x和b定义为一个2*1的矩阵，x.mm()是矩阵乘法\n",
    "import torch as t\n",
    "x = t.tensor([[1.0], [2.0]], requires_grad=True)\n",
    "\n",
    "A = t.tensor([[1.0, 1.0], \n",
    "              [1.0, 2.0]])\n",
    "b = t.tensor([[1.0], [0.0]])\n",
    "print(x, A, b)\n",
    "print()\n",
    "\n",
    "f = x.t().mm(A).mm(x) + x.t().mm(b)\n",
    "print(f)\n",
    "print()\n",
    "f.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.]], requires_grad=True) tensor([[3.],\n",
      "        [4.]], requires_grad=True) tensor([[1., 1.],\n",
      "        [1., 2.]]) tensor([[1.],\n",
      "        [0.]])\n",
      "\n",
      "tensor([[30.]], grad_fn=<AddBackward0>)\n",
      "\n",
      "tensor([[ 8.],\n",
      "        [11.]])\n",
      "tensor([[3.],\n",
      "        [5.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = t.tensor([[1.0], [2.0]], requires_grad=True)\n",
    "y = t.tensor([[3.0], [4.0]], requires_grad=True)\n",
    "\n",
    "A = t.tensor([[1.0, 1.0], \n",
    "              [1.0, 2.0]])\n",
    "b = t.tensor([[1.0], [0.0]])\n",
    "print(x, y, A, b)\n",
    "print()\n",
    "\n",
    "f = x.t().mm(A).mm(y) + x.t().mm(b)\n",
    "print(f)\n",
    "print()\n",
    "f.backward()\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.]]) tensor([[3.],\n",
      "        [4.]]) tensor([[ 2., 12.],\n",
      "        [ 1.,  2.]], requires_grad=True) tensor([[1.],\n",
      "        [0.]])\n",
      "\n",
      "tensor([[77.]], grad_fn=<AddBackward0>)\n",
      "\n",
      "tensor([[3., 4.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "# f(A) = x^T A y + x^T b\n",
    "x = t.tensor([[1.0], [2.0]])\n",
    "y = t.tensor([[3.0], [4.0]])\n",
    "\n",
    "A = t.tensor([[2.0, 12.0], \n",
    "              [1.0, 2.0]], requires_grad=True)\n",
    "b = t.tensor([[1.0], [0.0]])\n",
    "print(x, y, A, b)\n",
    "print()\n",
    "\n",
    "f = x.t().mm(A).mm(y) + x.t().mm(b)\n",
    "print(f)\n",
    "print()\n",
    "f.backward()\n",
    "#print(x.grad)\n",
    "#print(y.grad)\n",
    "print(A.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
