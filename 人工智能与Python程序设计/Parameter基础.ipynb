{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3670873-78c2-4352-bc20-ddb28342f8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb7dc37e-8928-46d6-90b8-b5f1b831ebdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade torchvision torch\n",
    "#!pip show torch\n",
    "#!conda install pytorch -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23aa0eb7-ead2-4436-bf01-113447d87f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9841, 0.6597, 0.5854, 0.6993],\n",
      "        [0.4593, 0.9126, 0.5498, 0.7071],\n",
      "        [0.8958, 0.0374, 0.2436, 0.2475]])\n",
      "a.shape =  torch.Size([3, 4])\n",
      "a.device =  cpu\n",
      "a.requires_grad =  False\n",
      "a.grad =  None\n",
      "a.grad_fn =  None\n",
      "a.is_leaf =  True\n"
     ]
    }
   ],
   "source": [
    "#print the attributes of a tensor\n",
    "a = torch.rand(3,4)\n",
    "print(a)\n",
    "print(\"a.shape = \", a.shape)\n",
    "print(\"a.device = \", a.device)\n",
    "print(\"a.requires_grad = \", a.requires_grad)\n",
    "print(\"a.grad = \", a.grad)\n",
    "print(\"a.grad_fn = \", a.grad_fn)\n",
    "print(\"a.is_leaf = \", a.is_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89bc8add-4c6c-4df1-9e0d-78cb662aa245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3488],\n",
      "        [1.9384],\n",
      "        [1.0908]], grad_fn=<MmBackward0>)\n",
      "b.shape =  torch.Size([3, 1])\n",
      "b.device =  cpu\n",
      "b.requires_grad =  True\n",
      "b.grad_fn =  <MmBackward0 object at 0x00000159E517BB20>\n",
      "b.is_leaf =  False\n"
     ]
    }
   ],
   "source": [
    "b = a.mm(torch.tensor([[1.0],[1.0],[1.0],[1.0]], requires_grad=True))\n",
    "print(b)\n",
    "print(\"b.shape = \", b.shape)\n",
    "print(\"b.device = \", b.device)\n",
    "print(\"b.requires_grad = \", b.requires_grad)\n",
    "#print(\"b.grad = \", b.grad)\n",
    "print(\"b.grad_fn = \", b.grad_fn)\n",
    "print(\"b.is_leaf = \", b.is_leaf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0abedeb9-459c-4262-9918-c746ca22e590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameter\n",
    "class TestParameter(nn.Module):#继承nn.Module\n",
    "    def __init__(self, in_dim): #构造函数，需要调用nn.Mudule的构造函数\n",
    "        super().__init__()       #等价于nn.Module.__init__()\n",
    "        self.w = nn.Parameter(torch.randn(in_dim+1, 1))\n",
    "        self.w1 = nn.Parameter(torch.randn(in_dim + 1, 1))\n",
    "        self.w2 = nn.Parameter(torch.randn(in_dim + 1, 1))\n",
    "        \n",
    "        print(\"w.size()=\", self.w.size())\n",
    "\n",
    "    def show_info(self, flag = True): \n",
    "        if flag:\n",
    "            for name, parameter in self.named_parameters():\n",
    "                print(name, '\\n', parameter, '\\n', parameter.data)\n",
    "        else:\n",
    "            for parameter in self.parameters():\n",
    "                print(parameter, '\\n', parameter.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddeddd1a-f6ea-4667-97fb-45530a36a86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.size()= torch.Size([4, 1])\n",
      "w \n",
      " Parameter containing:\n",
      "tensor([[0.9187],\n",
      "        [0.9665],\n",
      "        [0.6615],\n",
      "        [0.3141]], requires_grad=True) \n",
      " tensor([[0.9187],\n",
      "        [0.9665],\n",
      "        [0.6615],\n",
      "        [0.3141]])\n",
      "w1 \n",
      " Parameter containing:\n",
      "tensor([[ 1.4664],\n",
      "        [-0.5899],\n",
      "        [ 0.9677],\n",
      "        [-0.5392]], requires_grad=True) \n",
      " tensor([[ 1.4664],\n",
      "        [-0.5899],\n",
      "        [ 0.9677],\n",
      "        [-0.5392]])\n",
      "w2 \n",
      " Parameter containing:\n",
      "tensor([[ 0.1586],\n",
      "        [-0.7830],\n",
      "        [-0.4222],\n",
      "        [ 0.7269]], requires_grad=True) \n",
      " tensor([[ 0.1586],\n",
      "        [-0.7830],\n",
      "        [-0.4222],\n",
      "        [ 0.7269]])\n",
      "----------------------\n",
      "Parameter containing:\n",
      "tensor([[0.9187],\n",
      "        [0.9665],\n",
      "        [0.6615],\n",
      "        [0.3141]], requires_grad=True) \n",
      " tensor([[0.9187],\n",
      "        [0.9665],\n",
      "        [0.6615],\n",
      "        [0.3141]])\n",
      "Parameter containing:\n",
      "tensor([[ 1.4664],\n",
      "        [-0.5899],\n",
      "        [ 0.9677],\n",
      "        [-0.5392]], requires_grad=True) \n",
      " tensor([[ 1.4664],\n",
      "        [-0.5899],\n",
      "        [ 0.9677],\n",
      "        [-0.5392]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.1586],\n",
      "        [-0.7830],\n",
      "        [-0.4222],\n",
      "        [ 0.7269]], requires_grad=True) \n",
      " tensor([[ 0.1586],\n",
      "        [-0.7830],\n",
      "        [-0.4222],\n",
      "        [ 0.7269]])\n"
     ]
    }
   ],
   "source": [
    "tp = TestParameter(3)\n",
    "tp.show_info()\n",
    "print(\"----------------------\")\n",
    "tp.show_info(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36bccdd8-63b2-4269-9bed-4386a7c90602",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):#继承nn.Module\n",
    "    def __init__(self, in_dim): #构造函数，需要调用nn.Mudule的构造函数\n",
    "        super().__init__()       #等价于nn.Module.__init__()\n",
    "        self.w = nn.Parameter(torch.randn(in_dim+1, 1))\n",
    "        print(\"w.size()=\", self.w.size())\n",
    "\n",
    "    def forward(self, x): # x -> y\n",
    "        x = torch.cat([x, torch.ones((x.shape[0],1))], dim = 1)\n",
    "        y = x.matmul(self.w)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "401a0128-8b86-4fed-9fe7-48cbd9b21fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Recall the use of torch.cat\n",
    "a = torch.zeros(3,4)\n",
    "print(a)\n",
    "b = torch.cat([a, torch.ones((a.shape[0], 1))], dim = 1)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "446b1937-02f8-4fc5-9468-70cea5458263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w.size()= torch.Size([3, 1])\n",
      "calling layer(input)\n",
      "output\n",
      " tensor([[0.2116],\n",
      "        [1.6785]], grad_fn=<MmBackward0>)\n",
      "calling layer.forward(input)\n",
      "output\n",
      " tensor([[0.2116],\n",
      "        [1.6785]], grad_fn=<MmBackward0>)\n",
      "calling layer.__call__(input)\n",
      "output\n",
      " tensor([[0.2116],\n",
      "        [1.6785]], grad_fn=<MmBackward0>)\n",
      "w Parameter containing:\n",
      "tensor([[1.3568],\n",
      "        [1.8005],\n",
      "        [0.3485]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "def testForwardLR(in_dim, data_size = 2):\n",
    "    layer = LinearRegression(in_dim)\n",
    "    input=torch.randn(data_size,in_dim)\n",
    "    print(\"calling layer(input)\")\n",
    "    output=layer(input)  #前向传播 执行forward() ,  __call__\n",
    "    print(\"output\\n\", output)\n",
    "    print(\"calling layer.forward(input)\")\n",
    "    output=layer.forward(input)\n",
    "    print(\"output\\n\", output)\n",
    "    print(\"calling layer.__call__(input)\")\n",
    "    output=layer.__call__(input)\n",
    "    print(\"output\\n\", output)\n",
    "\n",
    "    #print(\"output\\n\", output)\n",
    "    for name, parameter in layer.named_parameters():\n",
    "        print(name, parameter)\n",
    "\n",
    "testForwardLR(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a1885a2-969a-4349-a9ae-ebc9bbfae8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3 ]\n"
     ]
    }
   ],
   "source": [
    "#Test the use of __call__()\n",
    "class CALL_TEST(object):\n",
    "    def __call__(self, x):\n",
    "        print(\"[\", x, \"]\")\n",
    "ct = CALL_TEST()\n",
    "ct(3)\n",
    "\n",
    "#nn.Module\n",
    "#def __call__(self, ...):\n",
    "    #forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ff0cf30-6109-4336-99b6-fb2e114b7b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The class to train and test the LinearRegression class\n",
    "class Linear_Model():\n",
    "    def __init__(self, in_dim):\n",
    "        \"\"\"\n",
    "        创建模型和优化器，初始化线性模型和优化器超参数\n",
    "        \"\"\"\n",
    "        self.learning_rate = 0.01\n",
    "        self.epoches = 1000\n",
    "        self.model = LinearRegression(in_dim) #torch.nn.Linear(in_dim,1)\n",
    "        self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.loss_function = torch.nn.MSELoss()\n",
    "\n",
    "    def train(self, x, y, if_plot = False):\n",
    "        \"\"\"\n",
    "        训练模型并保存参数\n",
    "        输入:\n",
    "            model_save_path: saved name of model\n",
    "            x: 训练数据\n",
    "            y: 回归真值\n",
    "        返回:\n",
    "            losses: 所有迭代中损失函数值\n",
    "        \"\"\"\n",
    "        losses = []\n",
    "        for epoch in range(self.epoches):\n",
    "            prediction = self.model(x) # forward, __call__  input->output\n",
    "\n",
    "            loss = self.loss_function(prediction, y)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward() #gradient\n",
    "            self.optimizer.step() #update\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            if epoch % 50 == 0:\n",
    "                print(\"epoch: {}, loss is: {}\".format(epoch, loss.item()))\n",
    "\n",
    "        if x.shape[1]==1 and if_plot:\n",
    "            plt.figure()\n",
    "            plt.scatter(x.numpy(), y.numpy())\n",
    "            plt.plot(x.numpy(), prediction.numpy(), color=\"r\")\n",
    "            plt.show()\n",
    "\n",
    "        return losses\n",
    "        \n",
    "    def test(self, x, y, if_plot = False):\n",
    "        \"\"\"\n",
    "        用保存或训练好的模型做测试\n",
    "        输入:\n",
    "            model_path: 训练好的模型的保存路径, e.g., \"linear.pth\"\n",
    "            x: 测试数据\n",
    "            y: 测试数据的回归真值\n",
    "        返回:\n",
    "            prediction: 测试数据的预测值\n",
    "        \"\"\"\n",
    "        prediction = self.model(x)\n",
    "        testMSE = self.loss_function(prediction, y)\n",
    "\n",
    "        if if_plot and x.shape[1]==1 and if_plot:\n",
    "            plt.figure()\n",
    "            plt.scatter(x.numpy(), y.numpy())\n",
    "            plt.plot(x.numpy(), prediction.numpy(), color=\"r\")\n",
    "            plt.show()\n",
    "\n",
    "        return prediction, testMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69449dc3-a447-4691-80e1-64fc7335a45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat the training and test datasets\n",
    "def create_linear_data(data_size, in_dim, if_plot = False):\n",
    "    \"\"\"\n",
    "    为线性模型生成数据\n",
    "    输入:\n",
    "        data_size: 样本数量\n",
    "    返回:\n",
    "        x_train: 训练数据\n",
    "        y_train: 训练数据回归真值\n",
    "        x_test: 测试数据\n",
    "        y_test: 测试数据回归真值\n",
    "    \"\"\"\n",
    "    np.random.seed(426)\n",
    "    torch.manual_seed(426)\n",
    "    #torch.cuda.manual_seed(426)\n",
    "\n",
    "    x = torch.Tensor(data_size, in_dim).uniform_(1,10)\n",
    "\n",
    "    w_true = torch.Tensor(in_dim, 1).uniform_(-5,5)\n",
    "    #map_true = torch.tensor([[1.5],[-5.],[3.]], dtype=torch.float32)\n",
    "    print('w真值:{}'.format(w_true))\n",
    "    \n",
    "    y = x.mm(w_true) + 10. + torch.FloatTensor(data_size, 1).normal_(0,10) #torch.randn(x.size())\n",
    "\n",
    "    shuffled_index = np.random.permutation(data_size)\n",
    "    #shuffled_index = torch.from_numpy(shuffled_index).long()\n",
    "    x = x[shuffled_index]\n",
    "    y = y[shuffled_index]\n",
    "    split_index = int(data_size * 0.7)\n",
    "    x_train = x[:split_index]\n",
    "    y_train = y[:split_index]\n",
    "    x_test = x[split_index:]\n",
    "    y_test = y[split_index:]\n",
    "\n",
    "    if if_plot and in_dim == 1:\n",
    "        plt.figure()\n",
    "        plt.scatter(x_train.numpy(),y_train.numpy())\n",
    "        plt.show()\n",
    "    return x_train, y_train, x_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d75bce76-1b97-4e8d-a198-026ad3db7c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w真值:tensor([[-4.4202],\n",
      "        [-3.3697]])\n",
      "hello\n",
      "torch.Size([70, 2]) torch.Size([30, 2])\n",
      "w.size()= torch.Size([3, 1])\n",
      "Start training\n",
      "epoch: 0, loss is: 1463.7684326171875\n",
      "epoch: 50, loss is: 92.34663391113281\n",
      "epoch: 100, loss is: 89.63218688964844\n",
      "epoch: 150, loss is: 87.42671203613281\n",
      "epoch: 200, loss is: 85.6347885131836\n",
      "epoch: 250, loss is: 84.17884063720703\n",
      "epoch: 300, loss is: 82.99589538574219\n",
      "epoch: 350, loss is: 82.0347671508789\n",
      "epoch: 400, loss is: 81.25385284423828\n",
      "epoch: 450, loss is: 80.61934661865234\n",
      "epoch: 500, loss is: 80.10382843017578\n",
      "epoch: 550, loss is: 79.68498229980469\n",
      "epoch: 600, loss is: 79.34465026855469\n",
      "epoch: 650, loss is: 79.0681381225586\n",
      "epoch: 700, loss is: 78.8434829711914\n",
      "epoch: 750, loss is: 78.66093444824219\n",
      "epoch: 800, loss is: 78.51263427734375\n",
      "epoch: 850, loss is: 78.39212799072266\n",
      "epoch: 900, loss is: 78.29422760009766\n",
      "epoch: 950, loss is: 78.21467590332031\n",
      "Finish training\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集上MSE损失值:63.47187805175781\n",
      "===============================\n",
      "w Parameter containing:\n",
      "tensor([[-4.7358],\n",
      "        [-3.2948],\n",
      "        [11.4932]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 生成数据\n",
    "data_size = 100\n",
    "in_dim = 2\n",
    "x_train, y_train, x_test, y_test = create_linear_data(data_size, in_dim, if_plot=False)\n",
    "\n",
    "print(\"hello\")\n",
    "print(x_train.shape, x_test.shape)\n",
    "\n",
    "# 线性回归模型实例化\n",
    "linear = Linear_Model(in_dim)\n",
    "\n",
    "# 模型训练\n",
    "print(\"Start training\")\n",
    "losses = linear.train(x_train, y_train)\n",
    "print(\"Finish training\")\n",
    "\n",
    "\n",
    "if_plot = True # set to True if you want to plot\n",
    "if if_plot:\n",
    "    plt.figure()\n",
    "    plt.scatter(np.arange(len(losses)), losses, marker='o', c='green')\n",
    "    plt.savefig('loss.jpg')\n",
    "    plt.show()\n",
    "# 模型测试\n",
    "prediction, testMSE = linear.test(x_test, y_test)\n",
    "print('测试集上MSE损失值:{}'.format(testMSE))\n",
    "\n",
    "\n",
    "print('===============================')\n",
    "for name, parameter in linear.model.named_parameters(): #named_parameters()  parameters()\n",
    "    print(name, parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a70e85-a1b7-44a5-b144-dd2ad9cc04ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d651bc1-8911-4508-b9a7-13eb686f94b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
